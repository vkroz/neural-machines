{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb40170",
   "metadata": {},
   "source": [
    "# Graded Lab : Tool Use and Reflective Agents\n",
    "\n",
    "In this lab, you will explore how AI agents can enhance research workflows by leveraging external tools and engaging in critical self-reflection. You'll learn how to build and integrate callable toolsâ€”such as web and academic search functions, and connect them to a language model using OpenAI's tool-calling API. Then, youâ€™ll guide the agent to not only generate content but also **reflect** on its own output, improving the quality and depth of the final report. By the end of this lab, you will have implemented a mini agent capable of searching, reasoning, and publishing structured reports in HTMLâ€”laying the foundation for more advanced multi-step and autonomous AI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ede51",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Learning Objectives\n",
    "\n",
    "By the end of this lab, you can:\n",
    "- Chain steps into a research pipeline (**search â†’ reflection â†’ formatting**).\n",
    "- Convert natural-language output into **styled HTML** suitable for sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd08fc44",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='submission'></a>\n",
    "\n",
    "<h4 style=\"color:green; font-weight:bold;\">TIPS FOR SUCCESSFUL GRADING OF YOUR ASSIGNMENT:</h4>\n",
    "\n",
    "* All cells are frozen except for the ones where you need to write your solution code or when explicitly mentioned you can interact with it.\n",
    "\n",
    "* In each exercise cell, look for comments `### START CODE HERE ###` and `### END CODE HERE ###`. These show you where to write the solution code. **Do not add or change any code that is outside these comments**.\n",
    "\n",
    "* You can add new cells to experiment but these will be omitted by the grader, so don't rely on newly created cells to host your solution code, use the provided places for this.\n",
    "\n",
    "* Avoid using global variables unless you absolutely have to. The grader tests your code in an isolated environment without running all cells from the top. As a result, global variables may be unavailable when scoring your submission. Global variables that are meant to be used will be defined in UPPERCASE.\n",
    "\n",
    "* To submit your notebook for grading, first save it by clicking the ðŸ’¾ icon on the top left of the page and then click on the <span style=\"background-color: red; color: white; padding: 3px 5px; font-size: 16px; border-radius: 5px;\">Submit assignment</span> button on the top right of the page.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b22668fb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 421,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Standard library imports\n",
    "# ================================\n",
    "import json\n",
    "\n",
    "# ================================\n",
    "# Third-party imports\n",
    "# ================================\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# ================================\n",
    "# Local / project imports\n",
    "# ================================\n",
    "import research_tools\n",
    "\n",
    "# ================================\n",
    "# Environment setup\n",
    "# ================================\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Instantiate OpenAI's client (you should use this in your graded functions)\n",
    "CLIENT = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe40a79",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 30
   },
   "outputs": [],
   "source": [
    "import unittests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c1bef",
   "metadata": {},
   "source": [
    "## Using Tools\n",
    "\n",
    "Youâ€™ll use two research tools exposed in the `research_tools` module:\n",
    "- **`arxiv_search_tool(query, max_results)`** â€“ academic papers via arXiv API.\n",
    "- **`tavily_search_tool(query, max_results, include_images)`** â€“ general web search via Tavily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacac323",
   "metadata": {},
   "source": [
    "Let's explore how the `arxiv_search_tool` works.\n",
    "\n",
    "This tool searches arXiv and returns a list of papers with:\n",
    "- `title`, `authors`, `published`, `summary`, `url`, and (if available) `link_pdf`.\n",
    "\n",
    "Below, we run a quick test and print the results in a readable format. Next cell is editable so feel free to try some search queries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d0eded",
   "metadata": {
    "deletable": false,
    "height": 336
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Paper 1\n",
      "  Title     : Linear Mappings of Free Algebra\n",
      "  Authors   : Aleks Kleyn\n",
      "  Published : 2010-03-08\n",
      "  URL       : http://arxiv.org/abs/1003.1544v2\n",
      "\n",
      "ðŸ“„ Paper 2\n",
      "  Title     : Non-linear positive maps between $C^*$-algebras\n",
      "  Authors   : Ali Dadkhah, Mox Sal Moslehian\n",
      "  Published : 2018-11-07\n",
      "  URL       : http://arxiv.org/abs/1811.03128v1\n",
      "\n",
      "ðŸ“„ Paper 3\n",
      "  Title     : GrÃ¼ss type inequalities for positive linear maps on $C^*$-algebras\n",
      "  Authors   : Ali Dadkhah, Mohammad Sal Moslehian\n",
      "  Published : 2016-10-12\n",
      "  URL       : http://arxiv.org/abs/1610.03868v1\n",
      "\n",
      "\n",
      "ðŸ§¾ Raw arxiv_Results:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"title\": \"Linear Mappings of Free Algebra\",\n",
      "    \"authors\": [\n",
      "      \"Aleks Kleyn\"\n",
      "    ],\n",
      "    \"published\": \"2010-03-08\",\n",
      "    \"url\": \"http://arxiv.org/abs/1003.1544v2\",\n",
      "    \"summary\": \"For arbitrary F-algebra, in which the operation of addition is defined, I explore biring of matrices of mappings. The sum of matrices is determined by the sum in F-algebra, and the product of matrices is determined by the product of mappings. The system of equations, whose matrix is a matrix of mappings, is called a system of additive equations. I considered the methods of solving system of additive equations. As an example, I consider the solution of a system of linear equations over the complex field provided that the equations contain unknown quantities and their conjugates.\\n  Linear mappings of algebra over a commutative ring preserve the operation of addition in algebra and the product of elements of the algebra by elements of the ring. The representation of tensor product A\\\\otimes A in algebra A generates the set of linear transformations of algebra A.\\n  The results of this research will be useful for mathematicians and physicists who deal with different algebras.\",\n",
      "    \"link_pdf\": null\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Non-linear positive maps between $C^*$-algebras\",\n",
      "    \"authors\": [\n",
      "      \"Ali Dadkhah\",\n",
      "      \"Mox Sal Moslehian\"\n",
      "    ],\n",
      "    \"published\": \"2018-11-07\",\n",
      "    \"url\": \"http://arxiv.org/abs/1811.03128v1\",\n",
      "    \"summary\": \"We present some properties of (not necessarily linear) positive maps between $C^*$-algebras. We first extend the notion of Lieb functions to that of Lieb positive maps between $C^*$-algebras. Then we give some basic properties and fundamental inequalities related to such maps. Next, we study $n$-positive maps ($n\\\\geq 2$). We show that if for a unital $3$-positive map $\\u03a6: \\\\mathscr{A}\\\\longrightarrow\\\\mathscr{B}$ between unital $C^*$-algebras and some $ A\\\\in \\\\mathscr{A}$ equality $\\u03a6(A^*A)= \\u03a6(A)^* \\u03a6(A)$ holds, then $\\u03a6(XA)=\\u03a6(X)\\u03a6(A)$ for all $X \\\\in \\\\mathscr{A}$. In addition, we prove that for a certain class of unital positive maps $\\u03a6: \\\\mathscr{A}\\\\longrightarrow\\\\mathscr{B}$ between unital $C^*$-algebras, the inequality $\\u03a6(\\u03b1A)\\\\leq\\u03b1\\u03a6(A)$ holds for all $ \\u03b1\\\\in [0,1]$ and all positive elements $ A\\\\in \\\\mathscr{A}$ if and only if $\\u03a6(0)=0$. Furthermore, we show that if for some $\\u03b1$ in the unit ball of $\\\\mathbb{C}$ or in $\\\\mathbb{R}_+$ with $|\\u03b1|\\\\neq 0,1$, the equality $\\u03a6(\\u03b1I)=\\u03b1I$ holds, then $\\u03a6$ is additive on positive elements of $\\\\mathscr{A}$. Moreover, we present a mild condition for a $6$-positive map, which ensures its linearity.\",\n",
      "    \"link_pdf\": null\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Gr\\u00fcss type inequalities for positive linear maps on $C^*$-algebras\",\n",
      "    \"authors\": [\n",
      "      \"Ali Dadkhah\",\n",
      "      \"Mohammad Sal Moslehian\"\n",
      "    ],\n",
      "    \"published\": \"2016-10-12\",\n",
      "    \"url\": \"http://arxiv.org/abs/1610.03868v1\",\n",
      "    \"summary\": \"Let $\\\\mathcal{A}$ and $\\\\mathcal{B}$ be two unital $C^*$-algebras and let for $C\\\\in\\\\mathcal{A},\\\\ \\u0393_C=\\\\{\\u03b3\\\\in \\\\mathbb{C} : \\\\|C-\\u03b3I\\\\|=\\\\inf_{\\u03b1\\\\in \\\\mathbb{C}} \\\\|C-\\u03b1I\\\\|\\\\}$. We prove that if $\\u03a6:\\\\mathcal{A} \\\\longrightarrow \\\\mathcal{B}$ is a unital positive linear map, then \\\\begin{eqnarray*} \\\\big|\\u03a6(AB)-\\u03a6(A)\\u03a6(B)\\\\big| \\\\leq \\\\big\\\\|\\u03a6(|A^*-\\u03b6I|^2)\\\\big\\\\|^\\\\frac{1}{2} \\\\big[\\u03a6(|B-\\u03beI|^2)\\\\big]^\\\\frac{1}{2} \\\\end{eqnarray*} for all $A,B\\\\in\\\\mathcal{A}, \\u03b6\\\\in \\u0393_A$ and $\\u03be\\\\in\\u0393_B.$\\\\\\\\ In addition, we show that if $(\\\\mathcal{A},\\u03c4)$ is a noncommutative probability space and $T \\\\in \\\\mathcal{A}$ is a density operator, then \\\\begin{eqnarray*} \\\\ \\\\ \\\\big|\\u03c4(TAB)-\\u03c4(TA)\\u03c4(TB)\\\\big|\\\\leq \\\\|A-\\u03b6I\\\\|_p\\\\|B-\\u03beI\\\\|_q\\\\|T\\\\|_r \\\\ \\\\ (p,q\\\\geq 4, r\\\\geq 2) \\\\end{eqnarray*} and \\\\begin{eqnarray*} \\\\big|\\u03c4(TAB)-\\u03c4(TA)\\u03c4(TB)\\\\big|\\\\leq \\\\|A-\\u03b6I\\\\|_p\\\\|B-\\u03beI\\\\|_q\\\\|T\\\\| \\\\ \\\\ \\\\ \\\\ (p,q\\\\geq 2)\\\\ \\\\ \\\\ \\\\ \\\\ \\\\end{eqnarray*} for every $A,B \\\\in \\\\mathcal{A}$ and $\\u03b6\\\\in \\u0393_A,\\u03be\\\\in \\u0393_B$. Our results generalize the corresponding results for matrices to operators on spaces of arbitrary dimension.\",\n",
      "    \"link_pdf\": null\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Test the arXiv search tool\n",
    "topic = \"linear algebra\"\n",
    "\n",
    "arxiv_results = research_tools.arxiv_search_tool(topic, max_results=3)\n",
    "\n",
    "# Show formatted arxiv_results\n",
    "for i, paper in enumerate(arxiv_results, 1):\n",
    "    if \"error\" in paper:\n",
    "        print(f\"âŒ Error: {paper['error']}\")\n",
    "    else:\n",
    "        print(f\"ðŸ“„ Paper {i}\")\n",
    "        print(f\"  Title     : {paper['title']}\")\n",
    "        print(f\"  Authors   : {', '.join(paper['authors'])}\")\n",
    "        print(f\"  Published : {paper['published']}\")\n",
    "        print(f\"  URL       : {paper['url']}\\n\")\n",
    "\n",
    "\n",
    "print(\"\\nðŸ§¾ Raw arxiv_Results:\\n\")\n",
    "print(json.dumps(arxiv_results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666fd399",
   "metadata": {},
   "source": [
    "The `tavily_search_tool` calls the Tavily API to fetch web results. Returns a list of dicts:\n",
    "- `title`, `content`, `url` (and optional image URLs when `include_images=True`).\n",
    "\n",
    "Run the cell to inspect sample output. Next cell is editable so feel free to try some search queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6e728e",
   "metadata": {
    "deletable": false,
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'What is Retrieval Augmented Generation (RAG)?', 'content': '* Learn how retrieval augmented generation (RAG) works by combining large language models (LLMs) with real-time, external data for more accurate and relevant outputs. Retrieval augmented generation (RAG) is a hybrid AI framework that bolsters large language models (LLMs) by combining them with external, up-to-date data sources. This process flow helps developers update data sources without retraining the model and makes RAG a scalable and cost-effective solution for building LLM applications in domains like customer support, knowledge bases and internal search. With RAG architecture, organizations can deploy any LLM model and augment it to return relevant results for their organization by giving it a small amount of their data without the costs and time of fine-tuning or pretraining the model.', 'url': 'https://www.databricks.com/glossary/retrieval-augmented-generation-rag'}\n",
      "{'title': 'What Is Retrieval-Augmented Generation aka RAG', 'content': 'Retrieval-augmented generation is a technique for enhancing the accuracy and reliability of generative AI models with information from specific and relevant data sources. The court clerk of AI is a process called retrieval-augmented generation, or RAG for short. Retrieval-augmented generation is a technique for enhancing the accuracy and reliability of generative AI models with information fetched from specific and relevant data sources. Retrieval-augmented generation gives models sources they can cite, like footnotes in a research paper, so users can check any claims. The NVIDIA AI Blueprint for RAG gives developers a foundational starting point for using NVIDIA NeMo Retriever models to build scalable, customizable data extraction and retrieval pipelines that deliver high accuracy and throughput.', 'url': 'https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/'}\n",
      "{'title': 'Top Use Cases of Retrieval-Augmented Generation (RAG) ...', 'content': \"* By integrating retrieval mechanisms with language generation, RAG systems produce more accurate and informative text outputs, significantly improving tasks like machine translation, question answering, and summarization. Retrieval augmented generation (RAG) is an artificial intelligence methodology that combines the power of neural language models with external knowledge resources to generate text that is relevant and informed. Retrieval augmented generation (RAG) operates by integrating a retrieval component into the language generation process, expanding the model's knowledge base beyond its initial training data. Retrieval augmented generation (RAG) significantly enhances the capabilities of natural language processing systems. For **question answering**, RAG employs its retrieval component to source relevant information before generating a response.\", 'url': 'https://www.glean.com/blog/retrieval-augmented-generation-use-cases'}\n",
      "{'title': 'Retrieval Augmented Generation (RAG) â€“ 5 Use Cases', 'content': 'In our last article, we discussed the impact of **Retrieval Augmented Generation (RAG)** systems in enhancing **Large Language Models (LLM)** by integrating dynamic information retrieval with generative processes. This new article will delve deeper into the practical applications of Retrieval Augmented Generation (RAG) systems, presenting five use cases across different industries and highlighting how these systems enhance data accessibility and streamline tasks and processes in real-world scenarios. **#2: Enhancing AI Avatars with Retrieval Augmented Generation (RAG)** Retrieval Augmented Generation (RAG) significantly improves AI avatars or digital humans by enabling them to access and utilize real-time, context-specific information during interactions. By integrating a retrieval component into generative models, RAG systems can pull from a vast repository of company-specific documents, training materials, and past queries to provide real-time, contextually relevant information to new hires.', 'url': 'https://theblue.ai/blog/rag-news/'}\n",
      "{'title': 'What is RAG (Retrieval-Augmented Generation)?', 'content': 'Retrieval-Augmented Generation (RAG) is the process of optimizing the output of a large language model, so it references an authoritative knowledge base outside of its training data sources before generating a response. It redirects the LLM to retrieve relevant information from authoritative, pre-determined knowledge sources. Developers can also restrict sensitive information retrieval to different authorization levels and ensure the LLM generates appropriate responses. Without RAG, the LLM takes the user input and creates a response based on information it was trained onâ€”or what it already knows. With RAG, an information retrieval component is introduced that utilizes the user input to first pull information from a new data source. Next, the RAG model augments the user input (or prompts) by adding the relevant retrieved data in context.', 'url': 'https://aws.amazon.com/what-is/retrieval-augmented-generation/'}\n"
     ]
    }
   ],
   "source": [
    "# Test the Tavily search tool\n",
    "topic = \"retrieval-augmented generation applications\"\n",
    "\n",
    "tavily_results = research_tools.tavily_search_tool(topic)\n",
    "for item in tavily_results:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7f628",
   "metadata": {},
   "source": [
    "## Tool Mapping\n",
    "\n",
    "In the next cell you will define a dictionary that maps tool names (strings) to the actual Python functions. This allows the model to call tools by name during tool-calling. This dictionary will be used in your first graded function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada2e9cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 98,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Tool mapping\n",
    "TOOL_MAPPING = {\n",
    "    \"tavily_search_tool\": research_tools.tavily_search_tool,\n",
    "    \"arxiv_search_tool\": research_tools.arxiv_search_tool,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed9e5e",
   "metadata": {},
   "source": [
    "## Exercise 1: Generate Research Report with Tools\n",
    "**Goal:** Implement `generate_research_report_with_tools(prompt)`.\n",
    "In this exercise, you'll work on a function that generates a detailed research report with the assistance of online tools. Focus on setting up interaction with the language model and handling the responses effectively.\n",
    "\n",
    "## Key Hints\n",
    "\n",
    "### 1. Setting Up the Chat with the Language Model\n",
    "- **Tool Selection**: Ensure that the tools are automatically selected by the model. Look into how to set `tool_choice` to \"auto\" within the function call. A helpful resource can be found in [OpenAIâ€™s Function Calling Documentation](https://platform.openai.com/docs/guides/function-calling#tool-choice).\n",
    "- **Parameter Configuration**: Consider the parameters already defined in your function, such as model, messages, and tools. Think about how these might be used in your setup.\n",
    "\n",
    "### 2. Recording Tool Call Results\n",
    "- **Understanding the `ChatCompletionMessage`** object will help you access the required attributes to save the messages. An example of `ChatCompletionMessage` looks like this: \n",
    "\n",
    "```python\n",
    "ChatCompletionMessage(\n",
    "    content=None,\n",
    "    refusal=None,\n",
    "    role='assistant',\n",
    "    annotations=[],\n",
    "    audio=None,\n",
    "    function_call=None,\n",
    "    tool_calls=[\n",
    "        ChatCompletionMessageFunctionToolCall(\n",
    "            id='call_ymMki5TBB91efJhMPjgoqjop',\n",
    "            function=Function(\n",
    "                arguments='{\"query\":\"radio observations of recurrent novae\",\"max_results\":5}',\n",
    "                name='arxiv_search_tool'\n",
    "            ),\n",
    "            type='function'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "```\n",
    "Assuming that `msg` if of type `ChatCompletionMessage`, if you wanted to get the `name` of a `tool_call` you can do something like:\n",
    "```python\n",
    " for call in msg.tool_calls:\n",
    "    tool_name = call.function.name\n",
    "```\n",
    "Finally, the `result` variable will be created by actually calling the function associated with each tool (`tool_func`).\n",
    "\n",
    "By leveraging these hints, you'll work towards an implementation that enables robust data gathering and report generation through smart tool integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b60ebc11",
   "metadata": {
    "deletable": false,
    "height": 1660,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: generate_research_report_with_tools\n",
    "from enum import auto\n",
    "\n",
    "\n",
    "def generate_research_report_with_tools(prompt: str, model: str = \"gpt-4o\") -> str:\n",
    "    \"\"\"\n",
    "    Generates a research report using OpenAI's tool-calling with arXiv and Tavily tools.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user prompt.\n",
    "        model (str): OpenAI model name.\n",
    "\n",
    "    Returns:\n",
    "        str: Final assistant research report text.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a research assistant that can search the web and arXiv to write detailed, \"\n",
    "                \"accurate, and properly sourced research reports.\\n\\n\"\n",
    "                \"ðŸ” Use tools when appropriate (e.g., to find scientific papers or web content).\\n\"\n",
    "                \"ðŸ“š Cite sources whenever relevant. Do NOT omit citations for brevity.\\n\"\n",
    "                \"ðŸŒ When possible, include full URLs (arXiv links, web sources, etc.).\\n\"\n",
    "                \"âœï¸ Use an academic tone, organize output into clearly labeled sections, and include \"\n",
    "                \"inline citations or footnotes as needed.\\n\"\n",
    "                \"ðŸš« Do not include placeholder text such as '(citation needed)' or '(citations omitted)'.\"\n",
    "            )\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # List of available tools\n",
    "    tools = [research_tools.arxiv_tool_def, research_tools.tavily_tool_def]\n",
    "\n",
    "    # Maximum number of turns\n",
    "    max_turns = 10\n",
    "    \n",
    "    # Iterate for max_turns iterations\n",
    "    for _ in range(max_turns):\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        # Chat with the LLM via the client and set the correct arguments. Hint: Their names match names of variables already defined.\n",
    "        # Make sure to let the LLM choose tools automatically. Hint: Look at the docs provided earlier!\n",
    "        response = CLIENT.chat.completions.create( \n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "            temperature=1, \n",
    "        ) \n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Get the response from the LLM and append to messages\n",
    "        msg = response.choices[0].message \n",
    "        messages.append(msg) \n",
    "\n",
    "        # Stop when the assistant returns a final answer (no tool calls)\n",
    "        if not msg.tool_calls:      \n",
    "            final_text = msg.content\n",
    "            print(\"âœ… Final answer:\")\n",
    "            print(final_text)\n",
    "            break\n",
    "\n",
    "        # Execute tool calls and append results\n",
    "        for call in msg.tool_calls:\n",
    "            tool_name = call.function.name\n",
    "            args = json.loads(call.function.arguments)\n",
    "            print(f\"ðŸ› ï¸ {tool_name}({args})\")\n",
    "\n",
    "            try:\n",
    "                tool_func = TOOL_MAPPING[tool_name]\n",
    "                result = tool_func(**args)\n",
    "            except Exception as e:\n",
    "                result = {\"error\": str(e)}\n",
    "\n",
    "            ### START CODE HERE ###\n",
    "\n",
    "            # Keep track of tool use in a new message\n",
    "            new_msg = { \n",
    "                # Set role to \"tool\" (plain string) to signal a tool was used\n",
    "                \"role\": \"tool\",\n",
    "                # As stated in the markdown when inspecting the ChatCompletionMessage object \n",
    "                # every call has an attribute called id\n",
    "                \"tool_call_id\": call.id,\n",
    "                # The name of the tool was already defined above, use that variable\n",
    "                \"name\": tool_name,\n",
    "                # Pass the result of calling the tool to json.dumps\n",
    "                \"content\": json.dumps(result)\n",
    "            }\n",
    "\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            # Append to messages\n",
    "            messages.append(new_msg)\n",
    "\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee23d21",
   "metadata": {},
   "source": [
    "Run the following cell to check the correctness of your code. It might take a while so don't worry if it takes a couple of minutes to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1af8aec5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 62
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ arxiv_search_tool({'query': 'radio observations of recurrent novae', 'max_results': 5})\n",
      "ðŸ› ï¸ tavily_search_tool({'query': 'radio observations of recurrent novae', 'max_results': 5})\n",
      "âœ… Final answer:\n",
      "## Radio Observations of Recurrent Novae\n",
      "\n",
      "Radio observations of recurrent novae are crucial for understanding the complex interactions between nova ejecta and their surrounding environments. Here are some key studies and findings:\n",
      "\n",
      "### 1. RS Ophiuchi Observations\n",
      "RS Ophiuchi is one of the most studied recurrent novae. A recent study utilized low-frequency radio observations with MeerKAT and LOFAR during the 2021 outburst. The observations were interpreted as synchrotron emission resulting from the shock interaction between nova ejecta and the circumbinary medium (source: [Inspire](https://inspirehep.net/literature/2626516)).\n",
      "\n",
      "### 2. The 2011 Outburst of T Pyxidis\n",
      "Another significant event was the 2011 outburst of the recurrent nova T Pyxidis. Radio observations during this outburst revealed details about the ejecta mass and hinted at complex mass loss processes. These data were gathered under the Astrophysics Data System, supported by the Smithsonian Astrophysical Observatory and NASA (source: [NASA ADS](https://ui.adsabs.harvard.edu/abs/2014ApJ...785...78N)).\n",
      "\n",
      "### 3. The First Radio Detection of RS Ophiuchi\n",
      "The first radio detection of an outburst from a recurrent nova was also associated with RS Ophiuchi. The detected brightness temperature indicated a non-thermal origin for the radio emission, differing from typical classical novae (source: [Nature](https://www.nature.com/articles/315306a0)).\n",
      "\n",
      "### 4. Historical Perspective on Radio Observations\n",
      "Radio observations of novae, including recurrent and classical types, date back to the 1970s. Initially, these were interpreted as thermal free-free emissions. The continuous development in radio astronomy has provided more insights into the dynamics of such explosive events (source: [IOP Science](https://iopscience.iop.org/article/10.3847/1538-4365/ac24ab/pdf)).\n",
      "\n",
      "These studies highlight the importance of radio observations in unraveling the mysteries surrounding recurrent novae, contributing to our understanding of their physical processes and the environments in which they occur.\n",
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_generate_research_report_with_tools(generate_research_report_with_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cb162d",
   "metadata": {},
   "source": [
    "## Exercise 2: Reflection + Rewrite\n",
    "\n",
    "**Goal:** Implement `reflection_and_rewrite(report)`.\n",
    "\n",
    "In this task, your goal is to develop a function that takes a report, analyzes it, generates a structured reflection, and produces an improved version of the report. This involves two main tasks: crafting a precise prompt and setting up a correctly configured response call to the language model.\n",
    "\n",
    "## Key Steps\n",
    "\n",
    "### 1. Create a User Prompt\n",
    "\n",
    "- **Objective**: Guide the language model to output a structured response in JSON format.\n",
    "- **Format**: Ensure the output includes two keys, `\"reflection\"` and `\"revised_report\"`.\n",
    "- **Details**: Your reflection should cover strengths, limitations, suggestions, and opportunities. The revised report should incorporate these elements to improve clarity and academic tone.\n",
    "\n",
    "### 2. Configure the Response Call\n",
    "\n",
    "- **Parameters**: Use the specified model (e.g., `\"gpt-4o-mini\"`) and set the temperature equal to the `temperature` parameter of the graded function.\n",
    "- **Structure**: Make sure the response setup directs the model properly, ensuring the JSON format is adhered to without additional commentary.\n",
    "\n",
    "\n",
    "By implementing these steps, your function will effectively transform and improve the given reports. Handle JSON parsing carefully to ensure the output is valid and reliable. Happy coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4585bcc6",
   "metadata": {
    "deletable": false,
    "height": 895,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: reflection_and_rewrite\n",
    "def reflection_and_rewrite(report, model: str = \"gpt-4o-mini\", temperature: float = 0.3) -> dict:\n",
    "    \"\"\"\n",
    "    Generates a structured reflection AND a revised research report.\n",
    "    Accepts raw text OR the messages list returned by generate_research_report_with_tools.\n",
    "\n",
    "    Returns:\n",
    "        dict with keys:\n",
    "          - \"reflection\": structured reflection text\n",
    "          - \"revised_report\": improved version of the input report\n",
    "    \"\"\"\n",
    "\n",
    "    # Input can be plain text or a list of messages, this function detects and parses accordingly\n",
    "    report = research_tools.parse_input(report)\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Define the prompt. A multi-line f-string is typically used for this.\n",
    "    # Remember it should ask the model to output ONLY valid JSON with this structure:\n",
    "    # {{ \"reflection\": \"<text>\", \"revised_report\": \"<text>\" }}\n",
    "    user_prompt = f\"\"\"Your task is to review draft report provided you below and provide:\n",
    "    1. A reflection on it. You must consider Strengths, Limitations, Suggestions, Opportunities\n",
    "    2. A revised report that addresses the issues mentioned in the reflection.\n",
    "    You MUST generate output strictly as a JSON object with the following structure:\n",
    "    {{ \"reflection\": \"<text>\", \"revised_report\": \"<text>\" }}\n",
    "\n",
    "    Draft report:\n",
    "    {report}\n",
    "    \"\"\"\n",
    "\n",
    "    # Get a response from the LLM\n",
    "    response = CLIENT.chat.completions.create( \n",
    "        # Pass in the model\n",
    "        model=model,\n",
    "        messages=[ \n",
    "            # System prompt is already defined\n",
    "            {\"role\": \"system\", \"content\": \"You are an academic reviewer and editor.\"},\n",
    "            # Add user prompt\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        # Set the temperature equal to the temperature parameter passed to the function\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Extract output\n",
    "    llm_output = response.choices[0].message.content.strip()\n",
    "\n",
    "    # Check if output is valid JSON\n",
    "    try:\n",
    "        data = json.loads(llm_output)\n",
    "    except json.JSONDecodeError:\n",
    "        raise Exception(\"The output of the LLM was not valid JSON. Adjust your prompt.\")\n",
    "\n",
    "    return {\n",
    "        \"reflection\": str(data.get(\"reflection\", \"\")).strip(),\n",
    "        \"revised_report\": str(data.get(\"revised_report\", \"\")).strip(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a563b04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_reflection_and_rewrite(reflection_and_rewrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c210d211",
   "metadata": {},
   "source": [
    "## Exercise 3: Convert Report to HTML\n",
    "**Goal:** Implement `convert_report_to_html(report)`.\n",
    "This exercise focuses on transforming a plain text research report into a well-structured HTML document. You will build a function to facilitate this conversion using a language model.\n",
    "\n",
    "## Key Steps\n",
    "\n",
    "### 1. Create a User Prompt\n",
    "- **Objective**: Instruct the model to transform plain text into HTML structure.\n",
    "- **Format**: Ensure the output is valid, clean HTML with appropriate section headers, formatted paragraphs, and clickable links.\n",
    "- **Details**: Preserve the citation style and request that the model responds only with HTML, without additional commentary.\n",
    "\n",
    "### 2. Configure the Response Call\n",
    "- **Parameters**: Use the specified model (e.g., `\"gpt-4o\"`) and set an appropriate temperature to balance creativity and accuracy.\n",
    "- **Structure**: Configure the `CLIENT.chat.completions.create` call properly, using both system and user prompts to ensure a clear and focused task description.\n",
    "\n",
    "By following these steps, you'll effectively convert plaintext reports into formatted HTML documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7548464",
   "metadata": {
    "deletable": false,
    "height": 504,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: convert_report_to_html\n",
    "def convert_report_to_html(report, model: str = \"gpt-4o\", temperature: float = 0.5) -> str:\n",
    "    \"\"\"\n",
    "    Converts a plaintext research report into a styled HTML page using OpenAI.\n",
    "    Accepts raw text OR the messages list from the tool-calling step.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input can be plain text or a list of messages, this function detects and parses accordingly\n",
    "    report = research_tools.parse_input(report)\n",
    "\n",
    "    # System prompt is already provided\n",
    "    system_prompt = \"You convert plaintext reports into full clean HTML documents.\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Build the user prompt instructing the model to return ONLY valid HTML\n",
    "    user_prompt = f\"\"\"\n",
    "    Your task: transform plain text into HTML structure.\n",
    "    Format: Ensure the output is valid, clean HTML with appropriate section headers, formatted paragraphs, and clickable links.\n",
    "    Details: Preserve the citation style and request that the model responds only with HTML, without additional commentary.\n",
    "\n",
    "    Input text to convert:\n",
    "    {report}\n",
    "    \"\"\"\n",
    "\n",
    "    # Call the LLM by interacting with the CLIENT. \n",
    "    # Remember to set the correct values for the model, messages (system and user prompts) and temperature\n",
    "    response = CLIENT.chat.completions.create( \n",
    "        # Pass in the model\n",
    "        model=model,\n",
    "        messages=[ \n",
    "            # System prompt is already defined\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            # Add user prompt\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        # Set the temperature equal to the temperature parameter passed to the function\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Extract the HTML from the assistant message\n",
    "    html = response.choices[0].message.content.strip()  \n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fe3c9c6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_convert_report_to_html(convert_report_to_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f5e51",
   "metadata": {},
   "source": [
    "### ðŸš€ End-to-End Pipeline\n",
    "\n",
    "Run this cell to execute the full workflow:\n",
    "\n",
    "1. Generate a research report (tools).\n",
    "2. Reflect on the report.\n",
    "3. Convert the report to HTML.\n",
    "\n",
    "> You should see the rendered HTML below and two concise reflections in the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f07e12e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 402
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ arxiv_search_tool({'query': 'radio observations of recurrent novae', 'max_results': 5})\n",
      "ðŸ› ï¸ tavily_search_tool({'query': 'radio observations of recurrent novae', 'max_results': 3})\n",
      "âœ… Final answer:\n",
      "## Radio Observations of Recurrent Novae\n",
      "\n",
      "Radio observations of recurrent novae provide valuable insights into the physical processes occurring during a nova outburst. These observations help understand the ejecta mass, mass loss processes, and interactions between the ejected materials and the surrounding environment.\n",
      "\n",
      "### Key Observations\n",
      "\n",
      "1. **RS Ophiuchi Observations**  \n",
      "   The recurrent nova RS Ophiuchi has been studied using low-frequency radio observations during its 2021 outburst. The data from instruments such as MeerKAT and LOFAR were utilized. The radio emission observed is primarily synchrotron emission, arising from the interaction between the nova ejecta and the circumbinary medium. This phenomenon allows researchers to model the shock interactions occurring during the nova outburst [InspireHEP](https://inspirehep.net/literature/2626516).\n",
      "\n",
      "2. **T Pyxidis 2011 Outburst**  \n",
      "   The 2011 outburst of the recurrent nova T Pyxidis provided an opportunity for extensive radio observations, which revealed details about the ejecta mass and suggested complex mass loss behaviors. The observations, recorded in various radio frequencies, were crucial in estimating the mass of material ejected and its implications on the nova system's evolution [ADS Harvard](https://ui.adsabs.harvard.edu/abs/2014ApJ...785...78N).\n",
      "\n",
      "3. **General Observations Across Classical and Recurrent Novae**  \n",
      "   While recurrent novae are rarer, observations are often limited to fewer events. However, the available radio observations of these events are crucial in improving our understanding of their unique emission characteristics. These emissions help differentiate recurrent events from classical novae and provide insights into their origins and evolutionary paths [ADS Harvard](https://adsabs.harvard.edu/full/1996ASPC...93..165B).\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Radio observations play a vital role in advancing our understanding of recurrent novae. By analyzing the emissions from these outbursts, researchers can gain insights into the underlying physical processes, such as mass ejection and shock interactions. Continued observations and modeling efforts are necessary to better understand these dynamic and complex phenomena.\n",
      "=== Research Report (preliminary) ===\n",
      "\n",
      "## Radio Observations of Recurrent Novae\n",
      "\n",
      "Radio observations of recurrent novae provide valuable insights into the physical processes occurring during a nova outburst. These observations help understand the ejecta mass, mass loss processes, and interactions between the ejected materials and the surrounding environment.\n",
      "\n",
      "### Key Observations\n",
      "\n",
      "1. **RS Ophiuchi Observations**  \n",
      "   The recurrent nova RS Ophiuchi has been studied using low-frequency radio observations during its 2021 outburst. The data from instruments such as MeerKAT and LOFAR were utilized. The radio emission observed is primarily synchrotron emission, arising from the interaction between the nova ejecta and the circumbinary medium. This phenomenon allows researchers to model the shock interactions occurring during the nova outburst [InspireHEP](https://inspirehep.net/literature/2626516).\n",
      "\n",
      "2. **T Pyxidis 2011 Outburst**  \n",
      "   The 2011 outburst of the recurrent nova T Pyxidis provided an opportunity for extensive radio observations, which revealed details about the ejecta mass and suggested complex mass loss behaviors. The observations, recorded in various radio frequencies, were crucial in estimating the mass of material ejected and its implications on the nova system's evolution [ADS Harvard](https://ui.adsabs.harvard.edu/abs/2014ApJ...785...78N).\n",
      "\n",
      "3. **General Observations Across Classical and Recurrent Novae**  \n",
      "   While recurrent novae are rarer, observations are often limited to fewer events. However, the available radio observations of these events are crucial in improving our understanding of their unique emission characteristics. These emissions help differentiate recurrent events from classical novae and provide insights into their origins and evolutionary paths [ADS Harvard](https://adsabs.harvard.edu/full/1996ASPC...93..165B).\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Radio observations play a vital role in advancing our understanding of recurrent novae. By analyzing the emissions from these outbursts, researchers can gain insights into the underlying physical processes, such as mass ejection and shock interactions. Continued observations and modeling efforts are necessary to better understand these dynamic and complex phenomena.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The output of the LLM was not valid JSON. Adjust your prompt.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mreflection_and_rewrite\u001b[39m\u001b[34m(report, model, temperature)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     data = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m json.JSONDecodeError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mise/installs/python/3.12.10/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mise/installs/python/3.12.10/lib/python3.12/json/decoder.py:338\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    336\u001b[39m \n\u001b[32m    337\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mise/installs/python/3.12.10/lib/python3.12/json/decoder.py:356\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(preliminary_report)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 2) Reflection on the report (use the final TEXT to avoid ambiguity)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m reflection_text = \u001b[43mreflection_and_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreliminary_report\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# <-- pass text, not messages\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Reflection on Report ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(reflection_text[\u001b[33m'\u001b[39m\u001b[33mreflection\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mreflection_and_rewrite\u001b[39m\u001b[34m(report, model, temperature)\u001b[39m\n\u001b[32m     52\u001b[39m     data = json.loads(llm_output)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m json.JSONDecodeError:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe output of the LLM was not valid JSON. Adjust your prompt.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     57\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreflection\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(data.get(\u001b[33m\"\u001b[39m\u001b[33mreflection\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)).strip(),\n\u001b[32m     58\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrevised_report\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(data.get(\u001b[33m\"\u001b[39m\u001b[33mrevised_report\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)).strip(),\n\u001b[32m     59\u001b[39m }\n",
      "\u001b[31mException\u001b[39m: The output of the LLM was not valid JSON. Adjust your prompt."
     ]
    }
   ],
   "source": [
    "# 1) Research with tools\n",
    "prompt_ = \"Radio observations of recurrent novae\"\n",
    "preliminary_report = generate_research_report_with_tools(prompt_)\n",
    "print(\"=== Research Report (preliminary) ===\\n\")\n",
    "print(preliminary_report)\n",
    "\n",
    "# 2) Reflection on the report (use the final TEXT to avoid ambiguity)\n",
    "reflection_text = reflection_and_rewrite(preliminary_report)   # <-- pass text, not messages\n",
    "print(\"=== Reflection on Report ===\\n\")\n",
    "print(reflection_text['reflection'], \"\\n\")\n",
    "print(\"=== Revised Report ===\\n\")\n",
    "print(reflection_text['revised_report'], \"\\n\")\n",
    "\n",
    "\n",
    "# 3) Convert the report to HTML (use the TEXT and correct function name)\n",
    "html = convert_report_to_html(reflection_text['revised_report'])\n",
    "\n",
    "print(\"=== Generated HTML (preview) ===\\n\")\n",
    "print((html or \"\")[:600], \"\\n... [truncated]\\n\")\n",
    "\n",
    "# 4) Display full HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00231efc",
   "metadata": {},
   "source": [
    "### ðŸ“Œ â€œExpected Outputâ€ note (for the notebook text cell)\n",
    "\n",
    "- `generate_research_report_with_tools` should return a **non-trivial string** (> 50 chars).\n",
    "\n",
    "- `reflection_and_rewrite` should return a **dict** with **'reflection'** and **'revised\\_report'** (both strings). The reflection should **mention** the four sections (Strengths, Limitations, Suggestions, Opportunities).\n",
    "\n",
    "- `convert_report_to_html` should return a **string that looks like HTML** (e.g., includes `<html>`, `<h1>`, `<p>`, or closing tags).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaad9ff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Wrap-Up\n",
    "\n",
    "You built a mini research agent that can:\n",
    "- ðŸ”Ž call tools (arXiv + Tavily),\n",
    "- ðŸ§  reflect on its own output,\n",
    "- ðŸ“° publish a clean HTML report.\n",
    "\n",
    "Great job!\n",
    "\n",
    "### What to Submit\n",
    "- Your notebook with Exercise 1â€“3 completed.\n",
    "\n",
    "### Troubleshooting (quick)\n",
    "- **Model/tool-call loop stalls?** Lower `max_turns` or print intermediate messages.\n",
    "- **HTML looks odd?** Re-run conversion with a fresh assistant response.\n",
    "\n",
    "**Youâ€™re doneâ€”nice work!** ðŸš€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678071d",
   "metadata": {},
   "source": [
    "## Check grading feedback\n",
    "\n",
    "If you have collapsed the right panel to have more screen space for your code, as shown below:\n",
    "\n",
    "<img src=\"./images/collapsed.png\" alt=\"Collapsed Image\" width=\"800\" height=\"400\"/>\n",
    "\n",
    "You can click on the left-facing arrow button (highlighted in red) to view feedback for your submission after submitting it for grading. Once expanded, it should display like this:\n",
    "\n",
    "<img src=\"./images/expanded.png\" alt=\"Expanded Image\" width=\"800\" height=\"400\"/>"
   ]
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
