{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334",
   "metadata": {},
   "source": [
    "# Lesson 3: Expand Data Agent Capabilities\n",
    "\n",
    "You can use [Cortex agents](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-agents) to retrieve data across unstructured and structured systems. In this example, the agent will answer questions from structured CRM data and unstructured meeting notes. This addition will empower your multi-agent system to be able to answer deeper questions requiring reasoning across many different data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855736c4",
   "metadata": {},
   "source": [
    "## 3.1 Load the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a5443f-467e-43d5-8fa5-10726d7e33e1",
   "metadata": {},
   "source": [
    "The environment variables include the OpenAI API and Tavily API keys, and the Snowflake credentials required to access the Snowflake account created for this course. The environment variables also define the name of the database where the provided data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e639fc4",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e30f48",
   "metadata": {},
   "source": [
    "**Notes**: \n",
    "\n",
    "- These variables are already defined in this environment. If you'd like to run the notebook locally, you can define them in a `.env` file. For an env template, you can check the file `env.template` in this lesson's folder.\n",
    "- To learn more about how the data was set up for this course, you can check this [guide](https://quickstarts.snowflake.com/guide/getting_started_with_cortex_agents/index.html#0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1c2f5f",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>To access <code>requirements.txt</code>, <code>env.template</code>, <code>prompts.py</code>, and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e607ffa4-c90e-4e28-8bd4-1ae660370206",
   "metadata": {},
   "source": [
    "## 3.2 Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1987a5d",
   "metadata": {},
   "source": [
    "The structured data (accessed via [Cortex Analyst](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-analyst)) is Customer Relationship Management (CRM) data, containing recent deals with values, company names, deal status, product lines, and more.\n",
    "\n",
    "The unstructured data (accessed via [Cortex Search](https://docs.snowflake.com/user-guide/snowflake-cortex/cortex-search/cortex-search-overview)) contains notes from meetings with these prospective customers.\n",
    "\n",
    "By using both the structured and unstructured data, you can ask analytical questions about recent deal values, uncover themes from the notes, or even combine the information to go even deeper.\n",
    "\n",
    "When combined with public data, you can uncover deep, actionable insights from your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bfdd23",
   "metadata": {},
   "source": [
    "### Structured data: CRM/deal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3fc3a3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from helper import snowpark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3542ed",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "snowpark_session.sql(\"USE WAREHOUSE SALES_INTELLIGENCE_WH\").collect()\n",
    "pd.DataFrame(snowpark_session.sql(\"select * from sales_intelligence.data.sales_metrics limit 5\").collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce666af3",
   "metadata": {},
   "source": [
    "### Unstructured data: meeting notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbba6f8",
   "metadata": {
    "height": 387
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "rows = snowpark_session.sql(\"\"\"\n",
    "    select transcript_text\n",
    "    from sales_intelligence.data.sales_conversations\n",
    "    limit 1\n",
    "\"\"\").collect()\n",
    "\n",
    "if not rows:\n",
    "    print(\"No transcripts found.\")\n",
    "else:\n",
    "    try:\n",
    "        transcript = rows[0]['TRANSCRIPT_TEXT']  # Snowflake usually uppercases column names\n",
    "    except Exception:\n",
    "        transcript = rows[0][0]\n",
    "\n",
    "    cleaned = \" \".join(transcript.split())  # collapse excessive whitespace/newlines\n",
    "    wrapped = textwrap.fill(cleaned, width=100)\n",
    "\n",
    "    print(\"=== Meeting Notes ===\\n\")\n",
    "    print(wrapped)\n",
    "    print(\"\\n=== End ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b61d32-0905-4d19-843e-7e6fe0a6af1b",
   "metadata": {},
   "source": [
    "## 3.3 Initialize Cortex Agent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a25c706",
   "metadata": {},
   "source": [
    "This agent will retrieve sales-related data from Snowflake using both Text2SQL (done by Cortex Analyst) and Semantic Search (done by Cortex Search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c42b194",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.core import Root\n",
    "from pydantic import BaseModel, PrivateAttr\n",
    "from snowflake.core.cortex.lite_agent_service import AgentRunRequest\n",
    "from typing import Any, Type\n",
    "from langchain.schema import HumanMessage\n",
    "from langgraph.graph import END\n",
    "from langgraph.types import Command\n",
    "from typing import Literal, Dict\n",
    "import json\n",
    "\n",
    "from helper import State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372b4d0d",
   "metadata": {},
   "source": [
    "- The Cortex Analyst uses a semantic model to perform text-to-SQL conversion. You can learn more about semantic models [here](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-analyst/semantic-model-spec). \n",
    "- To be able to perform semantic search across your unstructured data stored in Snowflake, you can create a [Cortex Search service](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-search/cortex-search-overview#create-the-service).\n",
    "\n",
    "To learn more about how the semantic model and the search service were created, you can check this [guide](https://quickstarts.snowflake.com/guide/getting_started_with_cortex_agents/index.html#0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9844865",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "SEMANTIC_MODEL_FILE = \"@sales_intelligence.data.models/sales_metrics_model.yaml\"\n",
    "\n",
    "CORTEX_SEARCH_SERVICE = \"sales_intelligence.data.sales_conversation_search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059aa688-30f8-4982-8e61-61d639060e62",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# ---- Agent Setup ----\n",
    "class CortexAgentArgs(BaseModel):\n",
    "    query: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf451ad8",
   "metadata": {
    "height": 1424
   },
   "outputs": [],
   "source": [
    "class CortexAgentTool:\n",
    "    name: str = \"CortexAgent\"\n",
    "    description: str = \"answers questions using sales conversations and metrics\"\n",
    "    args_schema: Type[CortexAgentArgs] = CortexAgentArgs\n",
    "\n",
    "    _session: Session = PrivateAttr()\n",
    "    _root: Root = PrivateAttr()\n",
    "    _agent_service: Any = PrivateAttr()\n",
    "\n",
    "    def __init__(self, session: Session):\n",
    "        self._session = session\n",
    "        self._root = Root(session)\n",
    "        self._agent_service = self._root.cortex_agent_service\n",
    "\n",
    "    def _build_request(self, query: str) -> AgentRunRequest:\n",
    "        return AgentRunRequest.from_dict({\n",
    "            \"model\": \"claude-3-5-sonnet\",\n",
    "            \"tools\": [\n",
    "                {\"tool_spec\": {\"type\": \"cortex_analyst_text_to_sql\", \"name\": \"analyst1\"}},\n",
    "                {\"tool_spec\": {\"type\": \"cortex_search\", \"name\": \"search1\"}},\n",
    "            ],\n",
    "            \"tool_resources\": {\n",
    "                \"analyst1\": {\"semantic_model_file\": SEMANTIC_MODEL_FILE},\n",
    "                \"search1\": {\n",
    "                    \"name\": CORTEX_SEARCH_SERVICE,\n",
    "                    \"max_results\": 10,\n",
    "                    \"id_column\": \"conversation_id\"\n",
    "                }\n",
    "            },\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": query}]}\n",
    "            ]\n",
    "        })\n",
    "\n",
    "    def _consume_stream(self, stream):\n",
    "        text, sql, citations = \"\", \"\", []\n",
    "        for evt in stream.events():\n",
    "            try:\n",
    "                delta = (evt.data.get(\"delta\") if isinstance(evt.data, dict)\n",
    "                         else json.loads(evt.data).get(\"delta\")\n",
    "                         or json.loads(evt.data).get(\"data\", {}).get(\"delta\"))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if not isinstance(delta, dict):\n",
    "                continue\n",
    "\n",
    "            for item in delta.get(\"content\", []):\n",
    "                if item.get(\"type\") == \"text\":\n",
    "                    text += item.get(\"text\", \"\")\n",
    "                elif item.get(\"type\") == \"tool_results\":\n",
    "                    for result in item[\"tool_results\"].get(\"content\", []):\n",
    "                        if result.get(\"type\") != \"json\":\n",
    "                            continue\n",
    "                        j = result[\"json\"]\n",
    "                        text += j.get(\"text\", \"\")\n",
    "                        sql = j.get(\"sql\", sql)\n",
    "                        citations.extend({\n",
    "                            \"source_id\": s.get(\"source_id\"),\n",
    "                            \"doc_id\": s.get(\"doc_id\")\n",
    "                        } for s in j.get(\"searchResults\", []))\n",
    "        return text, sql, str(citations)\n",
    "\n",
    "    def run(self, query: str, **kwargs):\n",
    "        \"\"\"\n",
    "        This agent will retrieve sales-related data from Snowflake using both Text2SQL and Semantic Search.\n",
    "        \"\"\"\n",
    "        req = self._build_request(query)\n",
    "        stream = self._agent_service.run(req)\n",
    "        text, sql, citations = self._consume_stream(stream)\n",
    "\n",
    "        results_str = \"\"\n",
    "        if sql:\n",
    "            try:\n",
    "                # Ensure warehouse is set explicitly before running the SQL\n",
    "                self._session.sql(\"USE WAREHOUSE SALES_INTELLIGENCE_WH\").collect()\n",
    "\n",
    "                df = self._session.sql(sql.rstrip(\";\")).to_pandas()\n",
    "                results_str = df.to_string(index=False)\n",
    "            except Exception as e:\n",
    "                results_str = f\"SQL execution error: {e}\"\n",
    "\n",
    "        return text, citations, sql, results_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a8829-9ef9-455c-b046-ca24dc08d245",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "cortex_agent_tool = CortexAgentTool(session=snowpark_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc8b641",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from helper import agent_system_prompt\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "cortex_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[cortex_agent_tool.run],\n",
    "    prompt=agent_system_prompt(f\"\"\"\n",
    "        You are the Researcher. You can answer questions \n",
    "        using customer deal data along with meeting notes.\n",
    "        Do not take any further action.\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf15e3c",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ </b> The following two queries might take a few minutes to output the results.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2495db1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> \n",
    "    <p>üö® &nbsp; <b>Different Run Results:</b> If the agent does not return the top 3 client deals and mentions it can't access the structured data, it could be because it did not choose the Cortex Analyst tool (which gives it access to the structured data containing client deals) and chose the Cortex Search tool instead (which gives it access to the meeting notes). You do not need to re-run the queries.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad02e085",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "agent_response = cortex_agent.invoke(\n",
    "    {\"messages\":\"what are our top 3 customer deals?\"})\n",
    "\n",
    "print(agent_response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0679ca3",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "agent_response = cortex_agent.invoke(\n",
    "    {\"messages\":\"what is the next step in the sales process for healthtech\"})\n",
    "\n",
    "print(agent_response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84acaa",
   "metadata": {},
   "source": [
    "Let's now wrap a LangGraph node around the react agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5785b00",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "def cortex_agents_research_node(\n",
    "    state: State,\n",
    ") -> Command[Literal[\"executor\"]]:\n",
    "    query = state.get(\"agent_query\", state.get(\"user_query\", \"\"))\n",
    "    # Call the tool with the string query\n",
    "    agent_response = cortex_agent.invoke({\"messages\":query})\n",
    "    # Compose a message content string with all results new HumanMessage with the result\n",
    "    new_message = HumanMessage(content=agent_response['messages'][-1].content, name=\"cortex_researcher\")\n",
    "    # Append to the message history\n",
    "    goto = \"executor\"\n",
    "    return Command(\n",
    "        update={\"messages\": [new_message]},\n",
    "        goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebd3d9a",
   "metadata": {},
   "source": [
    "## 3.4 Build the agent graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a229a233",
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "from helper import State, planner_node, executor_node, web_research_node, chart_node, chart_summary_node, synthesizer_node\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"planner\", planner_node)\n",
    "workflow.add_node(\"executor\", executor_node)\n",
    "workflow.add_node(\"web_researcher\", web_research_node)\n",
    "workflow.add_node(\"cortex_researcher\", cortex_agents_research_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "workflow.add_node(\"chart_summarizer\", chart_summary_node)\n",
    "workflow.add_node(\"synthesizer\", synthesizer_node)\n",
    "\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a2d5d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3b1fe",
   "metadata": {},
   "source": [
    "## 3.5 Use the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcb29f7-845d-4b24-949f-da7677f9ab5a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> \n",
    "<p>üö® &nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Your results may differ from those shown in the video.\n",
    "\n",
    "**It's expected for the agent to not answer perfectly**:\n",
    "\n",
    "- If the first query does not chart any results, or plots a chart showing companies A, B and C, or mentions that it doesn't have access to the required data, that's okay. It might be because the Cortex agent decided to choose the Cortex Search tool (access to meeting notes only) instead of the Cortex Analyst tool (access to client deals data). You do not need to re-run the queries.\n",
    "- The same applies to the second and third queries. If the agent does not return a perfect answer, that's okay. You do not need to re-run it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c1048",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ </b> The following three queries might take <b>2-5 minutes</b> to output the results.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c84b07",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "query = \"What are our top 3 customer deals? Chart the deal value for each.\"\n",
    "print(f\"Query: {query}\")\n",
    "state = {\n",
    "            \"messages\": [HumanMessage(content=query)],\n",
    "            \"user_query\": query,\n",
    "            \"enabled_agents\": [\"cortex_researcher\", \"web_researcher\", \"chart_generator\", \"chart_summarizer\", \"synthesizer\"],\n",
    "        }\n",
    "graph.invoke(state)\n",
    "\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536207c7",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "query = \"Identify our pending deals, research if they may be experiencing regulatory changes, and using the meeting notes for each customer, provide a new value proposition for each given the regulatory changes.\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "state = {\n",
    "            \"messages\": [HumanMessage(content=query)],\n",
    "            \"user_query\": query,\n",
    "            \"enabled_agents\": [\"cortex_researcher\", \"web_researcher\", \"chart_generator\", \"chart_summarizer\", \"synthesizer\"],\n",
    "        }\n",
    "graph.invoke(state)\n",
    "\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71472b28",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "query = \"Is there a common theme across our meeting notes?\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "state = {\n",
    "            \"messages\": [HumanMessage(content=query)],\n",
    "            \"user_query\": query,\n",
    "            \"enabled_agents\": [\"cortex_researcher\", \"web_researcher\", \"chart_generator\", \"chart_summarizer\", \"synthesizer\"],\n",
    "        }\n",
    "graph.invoke(state)\n",
    "\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c2c631",
   "metadata": {},
   "source": [
    "To ensure high quality, you need to add observability!\n",
    "\n",
    "In the next lesson, you'll add tracing and goal completion evaluation to understand your agent's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
