{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Matching service for e-Commerce\n",
    "\n",
    "- Requirements\n",
    "- Architecture Design\n",
    "- Data \n",
    "- Models\n",
    "- Serving\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Build a semantic search engine for a e-commerce.\n",
    "\n",
    "# Architecture Design\n",
    "\n",
    "We will use a \"two tower\" architecture and bi-encoder models for this task. \n",
    "\n",
    "**API:**\n",
    "Client interact with the service via REST API. Request body contains a query as free text. Responce contains a list of product ids sorted by relevance to the query.\n",
    "\n",
    "**Inference:**\n",
    "The product data is represented by vector embeddings and stored in the vector in HNSW graph.\n",
    "When user submits the query the query encoder converts the query into a vector. The we call the vector database to retrieve the top N most similar products.\n",
    "The resulting matchset is sorted by the similarity score and returned to the user.\n",
    "\n",
    "**Product Embeddings Generation:**\n",
    "We use HNSW for vector storage. The datasource for product data is a parquet file with the following columns:\n",
    "- product_id\n",
    "- product_title\n",
    "- product_description\n",
    "- product_bullet_point\n",
    "- product_brand\n",
    "- product_color\n",
    "The offline job reads the parquet file and converts the product data into a vector embeddings. The embeddings are stored in the vector database.\n",
    "\n",
    "**Model Training:**\n",
    "We use a bi-encoder model for this task. The model is trained on the training set and evaluated on the validation set.\n",
    "Base model: TK:all-MiniLM-L6-v2\n",
    "Tokenizer: TK:SentencePiece\n",
    "Model validation metrics: ESCI dataset, TK:(MAP@10, MRR@10, NDCG@10, Precision@10, Recall@10, F1@10)    \n",
    "Training algorithm: Contrastive loss\n",
    "\n",
    "**Datasets:**\n",
    "- ESCI dataset, that includes queries and products with relevance labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5653.89s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "shopping_queries_dataset_examples.parquet\n",
      "shopping_queries_dataset_products.parquet\n",
      "shopping_queries_dataset_sources.csv\n",
      "QUERIES:  /Users/vladimirkroz/datasets/shopping_queries_dataset/shopping_queries_dataset_examples.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>query</th>\n",
       "      <th>query_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_locale</th>\n",
       "      <th>esci_label</th>\n",
       "      <th>small_version</th>\n",
       "      <th>large_version</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>revent 80 cfm</td>\n",
       "      <td>0</td>\n",
       "      <td>B000MOO21W</td>\n",
       "      <td>us</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>revent 80 cfm</td>\n",
       "      <td>0</td>\n",
       "      <td>B07X3Y6B1V</td>\n",
       "      <td>us</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>revent 80 cfm</td>\n",
       "      <td>0</td>\n",
       "      <td>B07WDM7MQQ</td>\n",
       "      <td>us</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>revent 80 cfm</td>\n",
       "      <td>0</td>\n",
       "      <td>B07RH6Z8KW</td>\n",
       "      <td>us</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>revent 80 cfm</td>\n",
       "      <td>0</td>\n",
       "      <td>B07QJ7WYFQ</td>\n",
       "      <td>us</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example_id           query  query_id  product_id product_locale esci_label  \\\n",
       "0           0   revent 80 cfm         0  B000MOO21W             us          I   \n",
       "1           1   revent 80 cfm         0  B07X3Y6B1V             us          E   \n",
       "2           2   revent 80 cfm         0  B07WDM7MQQ             us          E   \n",
       "3           3   revent 80 cfm         0  B07RH6Z8KW             us          E   \n",
       "4           4   revent 80 cfm         0  B07QJ7WYFQ             us          E   \n",
       "\n",
       "   small_version  large_version  split  \n",
       "0              0              1  train  \n",
       "1              0              1  train  \n",
       "2              0              1  train  \n",
       "3              0              1  train  \n",
       "4              0              1  train  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ls ~/datasets/shopping_queries_dataset\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "config = {\n",
    "    'data_path': '/Users/vladimirkroz/datasets/shopping_queries_dataset',\n",
    "}\n",
    "\n",
    "config = {\n",
    "    **config,\n",
    "    'ds_queries': os.path.join(config['data_path'], 'shopping_queries_dataset_examples.parquet'),\n",
    "    'ds_products': os.path.join(config['data_path'], 'shopping_queries_dataset_products.parquet'),\n",
    "}\n",
    "\n",
    "print('QUERIES: ', config['ds_queries'])\n",
    "df = pd.read_parquet(config['ds_queries'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCTS:  /Users/vladimirkroz/datasets/shopping_queries_dataset/shopping_queries_dataset_products.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_bullet_point</th>\n",
       "      <th>product_brand</th>\n",
       "      <th>product_color</th>\n",
       "      <th>product_locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B079VKKJN7</td>\n",
       "      <td>11 Degrees de los Hombres Playera con Logo, Ne...</td>\n",
       "      <td>Esta playera con el logo de la marca Carrier d...</td>\n",
       "      <td>11 Degrees Negro Playera con logo\\nA estrenar ...</td>\n",
       "      <td>11 Degrees</td>\n",
       "      <td>Negro</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B079Y9VRKS</td>\n",
       "      <td>Camiseta Eleven Degrees Core TS White (M)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>11 Degrees</td>\n",
       "      <td>Blanco</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B07DP4LM9H</td>\n",
       "      <td>11 Degrees de los Hombres Core Pull Over Hoodi...</td>\n",
       "      <td>La sudadera con capucha Core Pull Over de 11 G...</td>\n",
       "      <td>11 Degrees Azul Core Pull Over Hoodie\\nA estre...</td>\n",
       "      <td>11 Degrees</td>\n",
       "      <td>Azul</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B07G37B9HP</td>\n",
       "      <td>11 Degrees Poli Panel Track Pant XL Black</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>11 Degrees</td>\n",
       "      <td>None</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B07LCTGDHY</td>\n",
       "      <td>11 Degrees Gorra Trucker Negro OSFA (Talla úni...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>11 Degrees</td>\n",
       "      <td>Negro (</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                      product_title  \\\n",
       "0  B079VKKJN7  11 Degrees de los Hombres Playera con Logo, Ne...   \n",
       "1  B079Y9VRKS          Camiseta Eleven Degrees Core TS White (M)   \n",
       "2  B07DP4LM9H  11 Degrees de los Hombres Core Pull Over Hoodi...   \n",
       "3  B07G37B9HP          11 Degrees Poli Panel Track Pant XL Black   \n",
       "4  B07LCTGDHY  11 Degrees Gorra Trucker Negro OSFA (Talla úni...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  Esta playera con el logo de la marca Carrier d...   \n",
       "1                                               None   \n",
       "2  La sudadera con capucha Core Pull Over de 11 G...   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                product_bullet_point product_brand  \\\n",
       "0  11 Degrees Negro Playera con logo\\nA estrenar ...    11 Degrees   \n",
       "1                                               None    11 Degrees   \n",
       "2  11 Degrees Azul Core Pull Over Hoodie\\nA estre...    11 Degrees   \n",
       "3                                               None    11 Degrees   \n",
       "4                                               None    11 Degrees   \n",
       "\n",
       "  product_color product_locale  \n",
       "0         Negro             es  \n",
       "1        Blanco             es  \n",
       "2          Azul             es  \n",
       "3          None             es  \n",
       "4       Negro (             es  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('PRODUCTS: ', config['ds_products'])\n",
    "df = pd.read_parquet(config['ds_products'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_path': '/Users/vladimirkroz/datasets/shopping_queries_dataset',\n",
       " 'ds_queries': '/Users/vladimirkroz/datasets/shopping_queries_dataset/shopping_queries_dataset_examples.parquet',\n",
       " 'ds_products': '/Users/vladimirkroz/datasets/shopping_queries_dataset/shopping_queries_dataset_products.parquet',\n",
       " 'model_name': 'xlm-roberta-base',\n",
       " 'batch_size': 32,\n",
       " 'epochs': 7,\n",
       " 'learning_rate': 2e-05,\n",
       " 'max_length': 128}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "# Merge with existing config dictionary\n",
    "config = {\n",
    "    **config,  # Existing config with data paths\n",
    "    'model_name': 'xlm-roberta-base',\n",
    "    'batch_size': 32, \n",
    "    'epochs': 7,\n",
    "    'learning_rate': 2e-5,\n",
    "    'max_length': 128\n",
    "}\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiEncoder Model\n",
    "\n",
    "class BiEncoder(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.query_encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.product_encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.projection = nn.Linear(self.query_encoder.config.hidden_size, 256)  # Project to smaller embedding size\n",
    "        \n",
    "    def encode_query(self, query_inputs):\n",
    "        outputs = self.query_encoder(**query_inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        return self.projection(cls_embedding)\n",
    "        \n",
    "    def encode_product(self, product_inputs):\n",
    "        outputs = self.product_encoder(**product_inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        return self.projection(cls_embedding)\n",
    "        \n",
    "    def forward(self, query_inputs, product_inputs):\n",
    "        query_emb = self.encode_query(query_inputs)\n",
    "        product_emb = self.encode_product(product_inputs)\n",
    "        return query_emb, product_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "\n",
    "class AmazonESCIDataset(Dataset):\n",
    "    def __init__(self, queries_df, products_df, tokenizer, max_length=128):\n",
    "        self.queries = queries_df\n",
    "        self.products = products_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.label_map = {'E': 1.0, 'S': 0.8, 'C': 0.3, 'I': 0.0}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.queries.iloc[idx]\n",
    "        query = row['query']\n",
    "        product_id = row['product_id']\n",
    "        \n",
    "        # Get product information\n",
    "        product = self.products[self.products['product_id'] == product_id].iloc[0]\n",
    "        \n",
    "        # Handle missing values safely\n",
    "        def safe_get(field):\n",
    "            value = product[field]\n",
    "            return value if isinstance(value, str) else ''\n",
    "            \n",
    "        product_text = (\n",
    "            \"Title: \" + safe_get('product_title') + \"; \" +\n",
    "            \"Description: \" + safe_get('product_description') + \"; \" +\n",
    "            \"Bullet Points: \" + safe_get('product_bullet_point')\n",
    "        )\n",
    "        \n",
    "        # Tokenize inputs\n",
    "        query_inputs = self.tokenizer(\n",
    "            query, \n",
    "            max_length=self.max_length, \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        product_inputs = self.tokenizer(\n",
    "            product_text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        label = torch.tensor(self.label_map[row['esci_label']], dtype=torch.float)\n",
    "        \n",
    "        return {\n",
    "            'query_inputs': {k: v.squeeze(0) for k, v in query_inputs.items()},\n",
    "            'product_inputs': {k: v.squeeze(0) for k, v in product_inputs.items()},\n",
    "            'label': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        query_inputs = {k: v.to(device) for k, v in batch['query_inputs'].items()}\n",
    "        product_inputs = {k: v.to(device) for k, v in batch['product_inputs'].items()}\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        query_emb, product_emb = model(query_inputs, product_inputs)\n",
    "        cos_sim = torch.nn.functional.cosine_similarity(query_emb, product_emb)\n",
    "        loss = criterion(cos_sim, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_path': '/Users/vladimirkroz/datasets/shopping_queries_dataset',\n",
       " 'ds_queries': '/Users/vladimirkroz/datasets/shopping_queries_dataset/shopping_queries_dataset_examples.parquet',\n",
       " 'ds_products': '/Users/vladimirkroz/datasets/shopping_queries_dataset/shopping_queries_dataset_products.parquet',\n",
       " 'model_name': 'xlm-roberta-base',\n",
       " 'batch_size': 32,\n",
       " 'epochs': 7,\n",
       " 'learning_rate': 2e-05,\n",
       " 'max_length': 128}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "\n",
    "# Load data\n",
    "products = pd.read_parquet(config['ds_products'])\n",
    "queries = pd.read_parquet(config['ds_queries'])\n",
    "\n",
    "# Filter and merge data\n",
    "queries = queries[queries['small_version'] == 1]\n",
    "merged_df = queries.merge(products, on=['product_id', 'product_locale'], how='inner')\n",
    "\n",
    "# Split data\n",
    "train_df = merged_df[merged_df['split'] == 'train']\n",
    "val_df = merged_df[merged_df['split'] == 'test']\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = AmazonESCIDataset(train_df, products, tokenizer, config['max_length'])\n",
    "val_dataset = AmazonESCIDataset(val_df, products, tokenizer, config['max_length'])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'])\n",
    "\n",
    "# Initialize model and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BiEncoder(config['model_name']).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    print(f'Epoch {epoch + 1}/{config[\"epochs\"]}, Loss: {train_loss:.4f}')\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'bi_encoder_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neumans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
